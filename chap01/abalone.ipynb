{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv \n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "np.seterr(invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize() -> None:\n",
    "    np.random.seed(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter 설정\n",
    "RND_MEAN = 0 \n",
    "RND_STD = 0.0030 # 가중치 파라미터를 초기화 할 때 이용함\n",
    "\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_abalone_dataset() -> None:\n",
    "    with open(\"/Users/hyeonjin/workspace/dataset/abalone/abalone.data.csv\") as f: # abalone 데이터셋이 존재하는 경로를 따라 csv 모듈로 로드\n",
    "        reader = csv.reader(f)\n",
    "        rows = []\n",
    "        for idx, row in enumerate(reader):\n",
    "            rows.append(row) # 데이터를 차례로 rows에 append\n",
    "\n",
    "    global data, input_cnt, output_cnt # 전역 변수 data, input_cnt, output_cnt 생성\n",
    "    input_cnt, output_cnt = 10, 1 # input_cnt 가 10인 이유는 성별을 나타내는 원핫 벡터 3개 + 7개의 데이터, output_cnt는 현미경으로 관찰한 고리 수, 라벨 데이터\n",
    "    data = np.zeros([len(rows), input_cnt+output_cnt]) # numpy 모듈로 4177행, 11열 모양을 갖는 영행렬 생성\n",
    "\n",
    "    for idx, row in enumerate(rows): # csv로 얻은 데이터를 numpy로 생성한 벡터에 parsing\n",
    "        # 성별에 따른 원핫 벡터 (모든 행에대해 0, 1, 2열) 생성\n",
    "        if row[0] == 'I': data[idx, 0] = 1\n",
    "        if row[0] == 'M': data[idx, 1] = 1\n",
    "        if row[0] == 'F': data[idx, 2] = 1\n",
    "        # 나머지 속성은 성별 뒤에 붙임\n",
    "        data[idx, 3:] = row[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model() -> None:\n",
    "    global weight, bias, input_cnt, output_cnt # 전역 변수로 wieght, bias 생성, load_abalone_dataset에서 생성한 input_cnt, output_cnt 사용\n",
    "    weight = np.random.normal(RND_MEAN, RND_STD, [input_cnt, output_cnt]) # RND_MEAN, RND_STD를 이용해 input_cnt * output_cnt 형태의 파라미터 생성\n",
    "    bias = np.zeros([output_cnt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_postproc(output, y):\n",
    "    # 회귀 분석에 맞추어 output과 y로부터 손실 함수 loss 계산\n",
    "    diff = output - y # 오차\n",
    "    square = np.square(diff) # 제곱\n",
    "    loss = np.mean(square) # 평균\n",
    "    return loss, diff\n",
    "\n",
    "def backprop_postproc(G_loss, diff):\n",
    "    shape = diff.shape\n",
    "\n",
    "    g_loss_square = np.ones(shape) / np.prod(shape)\n",
    "    g_square_diff = 2 * diff\n",
    "    g_diff_output = 1\n",
    "\n",
    "    G_square = g_loss_square * G_loss\n",
    "    G_diff = g_square_diff * G_square\n",
    "    G_output = g_diff_output * G_diff\n",
    "\n",
    "    return G_output\n",
    "\n",
    "def backprop_postproc_oneline(G_loss, diff):\n",
    "    return 2 * diff / np.prod(diff.shape)\n",
    "\n",
    "def eval_accuracy(output, y):\n",
    "    mdiff = np.mean(np.abs((output - y)/y))\n",
    "    return 1 - mdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_neuralnet(x):\n",
    "    global weight, bias # init_model에서 선언한 wight, bias를 이용\n",
    "    output = np.matmul(x, weight) + bias # XW + b 수행\n",
    "    return output, x\n",
    "\n",
    "def backprop_neuralnet(G_output, x): # 역전파 처리 함수, 순전파 출력 output에 대한 손실 기울기 G_output \n",
    "    global weight, bias # init_model에서 선언한 wegith, bias를 이용\n",
    "    g_output_w = x.transpose() # x를 이용해 x와 output 사이의 부분 기울기 g_output_w를 구함\n",
    "\n",
    "    G_w = np.matmul(g_output_w, G_output) # 부분 기울기와 손실 기울기를 이용해 weight 성분의 손실 기울기 구함\n",
    "    G_b = np.sum(G_output, axis=0)\n",
    "\n",
    "    weight -= LEARNING_RATE * G_w\n",
    "    bias -= LEARNING_RATE * G_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(x, y):\n",
    "    # 순전파 과정 수행\n",
    "    output, aux_nn = forward_neuralnet(x)\n",
    "    loss, aux_pp = forward_postproc(output, y)\n",
    "    accuracy = eval_accuracy(output, y)\n",
    "\n",
    "    G_loss = 1.0\n",
    "    G_output = backprop_postproc(G_loss, aux_pp)\n",
    "    backprop_neuralnet(G_output, aux_nn)\n",
    "\n",
    "    return loss, accuracy\n",
    "\n",
    "def run_test(x, y):\n",
    "    output, _ = forward_neuralnet(x)\n",
    "    accuracy = eval_accuracy(output, y)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_data(mb_size):\n",
    "    global data, shuffle_map, test_begin_idx # load_abalone_data 함수에서 생성한 data 전역 변수\n",
    "    shuffle_map = np.arange(data.shape[0]) # abalone data의 행 길이 만큼의 1차원 리스트 생성\n",
    "    np.random.shuffle(shuffle_map) # 리스트를 섞음\n",
    "    step_count = int(data.shape[0] * 0.8) // mb_size # 전체 데이터의 80퍼센트를 미니 배치 사이즈로 나누어 step_count 정의\n",
    "    test_begin_idx = step_count * mb_size # 테스트 데이터의 시작 인덱스 번호 생성\n",
    "    return step_count\n",
    "\n",
    "def get_test_data():\n",
    "    global data, shuffle_map, test_begin_idx, output_cnt # load_abalone_data와 arrage_data에서 생성한 변수들 사용\n",
    "    test_data = data[shuffle_map[test_begin_idx:]] # 테스트 데이터의 시작 위치를 이용해 test_data 생성\n",
    "    return test_data[:, :-output_cnt], test_data[:, -output_cnt] # 10개의 속성값이 x, 마지막 열이 label 데이터\n",
    "\n",
    "def get_train_data(mb_size, nth):\n",
    "    global data, shuffle_map, test_begin_idx, output_cnt # load_abalone_data, arrange_data에서 생성한 변수들 사용\n",
    "    if nth == 0: # 각 에폭의 첫 번째 호출일때 학습 데이터 부분에 대한 부분적인 순서를 섞어 에폭마다 다른 순서로 학습이 수행되게 함\n",
    "        np.random.shuffle(shuffle_map[:test_begin_idx])\n",
    "    \n",
    "    train_data = data[shuffle_map[mb_size*nth:mb_size*(nth+1)]]\n",
    "    return train_data[:, :-output_cnt], train_data[:, -output_cnt:] # 10개의 속성값이 x, 마지막 열이 label 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(epoch_count:int, mb_size:int, report:int) -> None:\n",
    "    step_count = arrange_data(mb_size)\n",
    "    test_x, test_y = get_test_data()\n",
    "\n",
    "    for epoch in range(epoch_count):\n",
    "        losses, accs = [], []\n",
    "\n",
    "        for n in range(step_count):\n",
    "            train_x, train_y = get_train_data(mb_size, n)\n",
    "            loss, acc = run_train(train_x, train_y)\n",
    "            losses.append(loss)\n",
    "            accs.append(acc)\n",
    "        \n",
    "        if report > 0 and (epoch+1) % report == 0:\n",
    "            acc = run_test(test_x, test_y)\n",
    "            print(f\"Epoch {epoch+1} loss={np.mean(losses):5.3f} accuracy={np.mean(accs):5.3f}/{acc:5.3f}.\")\n",
    "    \n",
    "    final_acc = run_test(test_x, test_y)\n",
    "    print(f\"\\nFinal Test: final accuracy = {final_acc:5.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abalone_exec(epoch_count:int=10, mb_size:int=10, report:int=1) -> None:\n",
    "    load_abalone_dataset() # 데이터셋 읽어들이는 load_abalone_dataset 실행\n",
    "    init_model() # 모델의 파라미터들을 초기화 하는 init_model 실행\n",
    "    train_and_test(epoch_count, mb_size, report) # 학습 및 평가 과정을 수행하는 train_and_test 함수 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss=33.875 accuracy=0.557/ -inf.\n",
      "Epoch 2 loss=8.226 accuracy=0.820/ -inf.\n",
      "Epoch 3 loss=7.582 accuracy=0.812/ -inf.\n",
      "Epoch 4 loss=7.475 accuracy=0.808/ -inf.\n",
      "Epoch 5 loss=7.395 accuracy=0.810/ -inf.\n",
      "Epoch 6 loss=7.328 accuracy=0.808/ -inf.\n",
      "Epoch 7 loss=7.269 accuracy=0.808/ -inf.\n",
      "Epoch 8 loss=7.217 accuracy=0.808/ -inf.\n",
      "Epoch 9 loss=7.175 accuracy=0.810/ -inf.\n",
      "Epoch 10 loss=7.135 accuracy=0.809/ -inf.\n",
      "\n",
      "Final Test: final accuracy =  -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/km/75btkg954xl31kcf44f3wzf40000gn/T/ipykernel_63011/2853326565.py:25: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  mdiff = np.mean(np.abs((output - y)/y))\n"
     ]
    }
   ],
   "source": [
    "abalone_exec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 loss=5.804 accuracy=0.825/ -inf.\n",
      "Epoch 40 loss=5.259 accuracy=0.834/ -inf.\n",
      "Epoch 60 loss=5.056 accuracy=0.837/ -inf.\n",
      "Epoch 80 loss=4.950 accuracy=0.838/ -inf.\n",
      "Epoch 100 loss=4.910 accuracy=0.840/ -inf.\n",
      "\n",
      "Final Test: final accuracy =  -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/km/75btkg954xl31kcf44f3wzf40000gn/T/ipykernel_63011/2853326565.py:25: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  mdiff = np.mean(np.abs((output - y)/y))\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.1\n",
    "abalone_exec(epoch_count=100, mb_size=100, report=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3bab46a45a0d910fd4817a596a6f54d475a6b641f2cf3c50900c986315bdf38e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
